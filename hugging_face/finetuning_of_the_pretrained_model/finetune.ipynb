{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration dataset-8702b8da36782627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/dataset to C:\\Users\\Knupf\\.cache\\huggingface\\datasets\\json\\dataset-8702b8da36782627\\0.0.0\\da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f46f95b1be9843f99d4f6d1412520ee3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b0d30e39b1b4b0c8058aa0e420ef39e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0 tables [00:00, ? tables/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6876487492c44816b4738a4def5f1232"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:\\Users\\Knupf\\.cache\\huggingface\\datasets\\json\\dataset-8702b8da36782627\\0.0.0\\da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a266612dc3e4c72bc6df0269b8ad4f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_function at 0x000001A8041DEF80> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97a81aa42a324efcbe2dbde74d0dea04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'question'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 31>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     25\u001B[0m dataset \u001B[38;5;241m=\u001B[39m load_dataset(\n\u001B[0;32m     26\u001B[0m     path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./dataset\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     27\u001B[0m     )\n\u001B[0;32m     29\u001B[0m dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m---> 31\u001B[0m tokenized_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreprocess_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumn_names\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m training_args \u001B[38;5;241m=\u001B[39m TrainingArguments(\n\u001B[0;32m     34\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./results\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     35\u001B[0m     evaluation_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     39\u001B[0m     num_train_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m     40\u001B[0m     weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, )\n\u001B[0;32m     41\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m     42\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     43\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     46\u001B[0m     tokenizer\u001B[38;5;241m=\u001B[39mtokenizer,\n\u001B[0;32m     47\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mdata_collator, )\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\venv\\lib\\site-packages\\datasets\\dataset_dict.py:770\u001B[0m, in \u001B[0;36mDatasetDict.map\u001B[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001B[0m\n\u001B[0;32m    767\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache_file_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    768\u001B[0m     cache_file_names \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m}\n\u001B[0;32m    769\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict(\n\u001B[1;32m--> 770\u001B[0m     {\n\u001B[0;32m    771\u001B[0m         k: dataset\u001B[38;5;241m.\u001B[39mmap(\n\u001B[0;32m    772\u001B[0m             function\u001B[38;5;241m=\u001B[39mfunction,\n\u001B[0;32m    773\u001B[0m             with_indices\u001B[38;5;241m=\u001B[39mwith_indices,\n\u001B[0;32m    774\u001B[0m             with_rank\u001B[38;5;241m=\u001B[39mwith_rank,\n\u001B[0;32m    775\u001B[0m             input_columns\u001B[38;5;241m=\u001B[39minput_columns,\n\u001B[0;32m    776\u001B[0m             batched\u001B[38;5;241m=\u001B[39mbatched,\n\u001B[0;32m    777\u001B[0m             batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m    778\u001B[0m             drop_last_batch\u001B[38;5;241m=\u001B[39mdrop_last_batch,\n\u001B[0;32m    779\u001B[0m             remove_columns\u001B[38;5;241m=\u001B[39mremove_columns,\n\u001B[0;32m    780\u001B[0m             keep_in_memory\u001B[38;5;241m=\u001B[39mkeep_in_memory,\n\u001B[0;32m    781\u001B[0m             load_from_cache_file\u001B[38;5;241m=\u001B[39mload_from_cache_file,\n\u001B[0;32m    782\u001B[0m             cache_file_name\u001B[38;5;241m=\u001B[39mcache_file_names[k],\n\u001B[0;32m    783\u001B[0m             writer_batch_size\u001B[38;5;241m=\u001B[39mwriter_batch_size,\n\u001B[0;32m    784\u001B[0m             features\u001B[38;5;241m=\u001B[39mfeatures,\n\u001B[0;32m    785\u001B[0m             disable_nullable\u001B[38;5;241m=\u001B[39mdisable_nullable,\n\u001B[0;32m    786\u001B[0m             fn_kwargs\u001B[38;5;241m=\u001B[39mfn_kwargs,\n\u001B[0;32m    787\u001B[0m             num_proc\u001B[38;5;241m=\u001B[39mnum_proc,\n\u001B[0;32m    788\u001B[0m             desc\u001B[38;5;241m=\u001B[39mdesc,\n\u001B[0;32m    789\u001B[0m         )\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, dataset \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m    791\u001B[0m     }\n\u001B[0;32m    792\u001B[0m )\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\venv\\lib\\site-packages\\datasets\\dataset_dict.py:771\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    767\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache_file_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    768\u001B[0m     cache_file_names \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m}\n\u001B[0;32m    769\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict(\n\u001B[0;32m    770\u001B[0m     {\n\u001B[1;32m--> 771\u001B[0m         k: \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    772\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    773\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    774\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    775\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    776\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    777\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    778\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[43m            \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremove_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    780\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    781\u001B[0m \u001B[43m            \u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    782\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_file_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_file_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    783\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    784\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    785\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    786\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    787\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, dataset \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m    791\u001B[0m     }\n\u001B[0;32m    792\u001B[0m )\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:2376\u001B[0m, in \u001B[0;36mDataset.map\u001B[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[0;32m   2373\u001B[0m disable_tqdm \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m logging\u001B[38;5;241m.\u001B[39mis_progress_bar_enabled()\n\u001B[0;32m   2375\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_proc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m num_proc \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m-> 2376\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_single\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2377\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2378\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2379\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2380\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2381\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2384\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremove_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2385\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2387\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_file_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_file_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2388\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2389\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2390\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2391\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2392\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnew_fingerprint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_fingerprint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2393\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdisable_tqdm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_tqdm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2394\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2395\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2396\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2398\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_cache_file_name\u001B[39m(cache_file_name, rank):\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:551\u001B[0m, in \u001B[0;36mtransmit_tasks.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    549\u001B[0m     \u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    550\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[1;32m--> 551\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    552\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[0;32m    553\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n\u001B[0;32m    554\u001B[0m     \u001B[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:518\u001B[0m, in \u001B[0;36mtransmit_format.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    511\u001B[0m self_format \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type,\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_kwargs,\n\u001B[0;32m    514\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_columns,\n\u001B[0;32m    515\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_all_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_all_columns,\n\u001B[0;32m    516\u001B[0m }\n\u001B[0;32m    517\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[1;32m--> 518\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    519\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[0;32m    520\u001B[0m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\venv\\lib\\site-packages\\datasets\\fingerprint.py:458\u001B[0m, in \u001B[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    452\u001B[0m             kwargs[fingerprint_name] \u001B[38;5;241m=\u001B[39m update_fingerprint(\n\u001B[0;32m    453\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fingerprint, transform, kwargs_for_fingerprint\n\u001B[0;32m    454\u001B[0m             )\n\u001B[0;32m    456\u001B[0m \u001B[38;5;66;03m# Call actual function\u001B[39;00m\n\u001B[1;32m--> 458\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    460\u001B[0m \u001B[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001B[39;00m\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:  \u001B[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:2764\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001B[0m\n\u001B[0;32m   2760\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[0;32m   2761\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mslice\u001B[39m(i, i \u001B[38;5;241m+\u001B[39m batch_size)\u001B[38;5;241m.\u001B[39mindices(input_dataset\u001B[38;5;241m.\u001B[39mnum_rows)))\n\u001B[0;32m   2762\u001B[0m )  \u001B[38;5;66;03m# Something simpler?\u001B[39;00m\n\u001B[0;32m   2763\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 2764\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[43mapply_function_on_filtered_inputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2765\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2766\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2767\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_same_num_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_indexes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2768\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2769\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2770\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NumExamplesMismatchError:\n\u001B[0;32m   2771\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetTransformationNotAllowedError(\n\u001B[0;32m   2772\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2773\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:2644\u001B[0m, in \u001B[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[1;34m(inputs, indices, check_same_num_examples, offset)\u001B[0m\n\u001B[0;32m   2642\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[0;32m   2643\u001B[0m     additional_args \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (rank,)\n\u001B[1;32m-> 2644\u001B[0m processed_inputs \u001B[38;5;241m=\u001B[39m function(\u001B[38;5;241m*\u001B[39mfn_args, \u001B[38;5;241m*\u001B[39madditional_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfn_kwargs)\n\u001B[0;32m   2645\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m update_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2646\u001B[0m     \u001B[38;5;66;03m# Check if the function returns updated examples\u001B[39;00m\n\u001B[0;32m   2647\u001B[0m     update_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, (Mapping, pa\u001B[38;5;241m.\u001B[39mTable))\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:2336\u001B[0m, in \u001B[0;36mDataset.map.<locals>.decorate.<locals>.decorated\u001B[1;34m(item, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2332\u001B[0m decorated_item \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   2333\u001B[0m     Example(item, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m batched \u001B[38;5;28;01melse\u001B[39;00m Batch(item, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[0;32m   2334\u001B[0m )\n\u001B[0;32m   2335\u001B[0m \u001B[38;5;66;03m# Use the LazyDict internally, while mapping the function\u001B[39;00m\n\u001B[1;32m-> 2336\u001B[0m result \u001B[38;5;241m=\u001B[39m f(decorated_item, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2337\u001B[0m \u001B[38;5;66;03m# Return a standard dict\u001B[39;00m\n\u001B[0;32m   2338\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, LazyDict) \u001B[38;5;28;01melse\u001B[39;00m result\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\hugging_face\\finetuning_of_the_pretrained_model\\preprocessing.py:9\u001B[0m, in \u001B[0;36mpreprocess_function\u001B[1;34m(examples)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess_function\u001B[39m(examples):\n\u001B[1;32m----> 9\u001B[0m     questions \u001B[38;5;241m=\u001B[39m [q\u001B[38;5;241m.\u001B[39mstrip() \u001B[38;5;28;01mfor\u001B[39;00m q \u001B[38;5;129;01min\u001B[39;00m \u001B[43mexamples\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mquestion\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m]\n\u001B[0;32m     10\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m tokenizer(\n\u001B[0;32m     11\u001B[0m         questions,\n\u001B[0;32m     12\u001B[0m         examples[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     16\u001B[0m         padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m         )\n\u001B[0;32m     19\u001B[0m     offset_mapping \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moffset_mapping\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\chatbot_project\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:132\u001B[0m, in \u001B[0;36mBatch.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m--> 132\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures \u001B[38;5;129;01mand\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures:\n\u001B[0;32m    134\u001B[0m         values \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    135\u001B[0m             decode_nested_example(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures[key], value) \u001B[38;5;28;01mif\u001B[39;00m value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m value \u001B[38;5;129;01min\u001B[39;00m values\n\u001B[0;32m    136\u001B[0m         ]\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.1520.0_x64__qbz5n2kfra8p0\\lib\\collections\\__init__.py:1106\u001B[0m, in \u001B[0;36mUserDict.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__missing__\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m   1105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__missing__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key)\n\u001B[1;32m-> 1106\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'question'"
     ]
    }
   ],
   "source": [
    "from hugging_face.get_transformer_model_path import get_transformer_model_path\n",
    "from hugging_face.finetuning_of_the_pretrained_model.preprocessing import preprocess_function\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer, DefaultDataCollator\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(get_transformer_model_path())\n",
    "\n",
    "# import torch\n",
    "# from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
    "# # Same as before\n",
    "checkpoint = get_transformer_model_path()\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(checkpoint)\n",
    "# sequences = [    \"I've been waiting for a HuggingFace course my whole life.\",    \"This course is amazing!\",]\n",
    "# batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "# # This is new\n",
    "# batch[\"labels\"] = torch.tensor([1, 1])\n",
    "# optimizer = AdamW(model.parameters())\n",
    "# loss = model(**batch).loss\n",
    "# loss.backward()\n",
    "# optimizer.step()\n",
    "\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "dataset = load_dataset(\n",
    "    path='./dataset'\n",
    "    )\n",
    "\n",
    "dataset[\"train\"][0]\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01, )\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, )\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}